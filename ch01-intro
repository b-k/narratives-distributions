
NewMMS(N2D~~<|\paragraph{$1}\label{m4_translit(<|$2|>~~'
')}\leavevmode\\

Narrative: $3

Distribution: $4

m4_ifelse(<|$5|>~~<||>~~~~<|Notes: $5|>)

|>~~<|<div class="h2d"><a name="<||>m4_translit(<|$2|>~~'
')"></a>Paragraph($1)

<em>Narrative</em>: $3

<em>Distribution</em>: $4

m4_ifelse(<|$5|>~~<||>~~~~<|<em>Notes</em>: $5|>)
</div>|>)




This project lists open-form narratives and the closed-form distributions that
approximate them. Its intent is to help you build estimable statistical models on a sound
micro-level foundation.


Here is a simple example of going from a real-world situation to an estimable mathematical model:

N2D(A sample narrative~~samp~~
Make a large series of independent, identically distributed (iid) draws from a source.
Take the mean of those draws.
~~
The distribution of repeated means will be a Normal distribution.
)

If you wanted to write a simulation, in which individual agents each experience some iid
shock and their mean level is measured and reported, this wonderful piece of mathematics
just saved you the trouble.

Now you can focus your energies on the more novel parts of the storyline. Of course,
those too may have closed-form shortcuts that save you the trouble of writing down an
open-form simulation. Your final model may wind up being a combination of closed-form
submodels.

None of this is novel, and every narrative-to-distribution should have a
reference to an existing work, (including Wikipedia, because this is uncontroversial,
textbook stuff). However, it is being presented in what seems to be a novel way, to
facilitate the development of detailed micro-level narratives using known bulding
blocks where they are available.

The fact that we are relying on so many existing sources means that we don't need to
provide proofs here, unless they are useful for elucidating the transformation.

Also, estimation is often not a trivial matter. Some of these examples may break for
small $N$. We may add these notes later, but at this stage it would be nice to just get
down as many narratives as possible, and leave the estimation details to the references.
TeX(\def\Re{{\ensuremath{\mathbb R}}\xspace}
        \def\datas{\ensuremath{{\mathbb D}}\xspace}
        \def\params{\ensuremath{{\mathbb P}}\xspace}
        \def\models{\ensuremath{{\mathbb M}}\xspace}
        \def\mod#1{\ensuremath{M_{#1}}\xspace})
HTML($\def\Re{{\mathbb R}}
        \def\datas{{\mathbb D}}
        \def\params{{\mathbb P}}
        \def\models{{\mathbb M}}
        \def\mod#1{M_{#1}}$)

bf(Q: Where's the $\chi^2$ distribution?) Given a series of $n$ Normally distributed
variables, the sum of their squares has a $\chi^2_n$ Distribution. So one could
conceivably describe a micro-level narrative that produces a $\chi^2$ outcome based
on the Normal narrative, but it is a rather convoluted storyline: start with $n$
iid sets, make distinct pools of draws from each of them, take their separate means,
take the square of each mean, then sum the squares. Here is Citet(kmenta~~Kmenta) on
the implausibility of this storyline: ``There are no noted parent populations whose
distributions could be described by the chi-squared distribution.'' The process by which a
$\chi^2$ Distribution is generated is therefore best described as a transformation of
existing distributions, not as a micro-level narrative.

This list will not cover methods by which one distribution can be transformed into
another. Stats textbooks and Wikipedia do a fine job on transforming distributions to
other distributions, so we leave that level of work out of scope.

Comment(
Paragraph(A note on notation)
The Normal distribution is a mapping of the form $f:(\mu, \sigma, x)
\to \Re^+$. We could also fix $\mu$ and $\sigma$, which produces a univariate function
$f:x\to\Re^+$, which makes use of a meta-function of the form $N:(\mu, \sigma) \to
(f:x\to\Re^+)$. Textbooks (and Wikipedia) often characterize ``the Gaussian distribution''
to indicate this meta-function that produces a series of Gaussian distribution functions
depending on the values to which $\mu$ and $\sigma$ have been fixed.

This document defines the Gaussian distribution as the mapping $f:(\mu, \sigma, x) \to \Re^+$.
Notationally, this means that the distribution would be written with three inputs,
$f(\mu, \sigma, x)$, where we understand all but the last inputs to be parameters, and the
last input to be observed data. Grammaticaly, this means that a distribution is a unique
entity (a single point in the space of functions), not a collection or class of
similar entities, and this implies that distribution names should be capitalized under
common English grammatical rules.

It would be equally coherent to describe the family of Gaussian distributions, where
fixing $\mu=3$ and $\sigma=2$ (for example) produces a single Gaussian distribution,
often notated with something like ${\cal N}(3, 2)$, with the understanding that this
is a univariate function $x\to\Re^+$.  In the notation here, that distribution would
be written as ${\cal N}(3, 2, x)$.
)
